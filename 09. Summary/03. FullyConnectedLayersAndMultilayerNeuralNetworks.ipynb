{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 완전 연결층과 다층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 완전 연결층은 여러 노드들과 노드들 사이의 에지(Edge)로 구성\n",
    "- 완전 연결층만을 사용하는 딥러닝 모델은 다층 신경망(Multi-Layer Perceptron: MLP)이라고 불리며, 오래전부터 인공지능시스템의 구현에 사용됐음\n",
    "- 완전 연결층 내부는 전달 받은 입력 데이터를 보관하는 '입력 노드', 다음 층으로 데이터를 전달하기 위한 '출력 노드', 그리고 이 두 종류의 노드를 연결하는 '에지'들로 이루어져 있음\n",
    "- 각각의 에지는 값을 가지고 있는데, 이 값을 '가중치(Weight)'라고 함\n",
    "- 완전 연결층은 전달받은 입력 데이터에 가중치를 곱하고 합산하여 출력값을 만듦\n",
    "- 다층 신경망은 네트워크층의 개수, 각 내부 노드의 갯수가 많아질수록 더 복잡한 데이터를 학습할 수 있음\n",
    "- 주어지는 입력이 모델에 전달되어 최종 노드에까지 전달되어 출력을 발생시키는 과정을 '전파(Propagation)'라고 함\n",
    "- 이 전파 과정을 통해 특정 데이터에 대한 신경망의 출력값을 확인할 수 있으며, 실제 출력을 기대했던 값, 즉 정답 데이터와 비교해서 오차(Error)값을 계산할 수 있음\n",
    "- 신경망 모델의 학습은 이 오차 값을 최소화시키는 방향으로 이루어지게 되는데, 이를 위해 오차(Error)를 모델에 역방향으로 전달시켜 각 에지의 값을 조금씩 바꾸는 방식이 사용되는데, 이 과정을 '역전파(Back-Propagation)'라고 함\n",
    "- 딥러닝의 학습은 여러 개의 입력데이터에 대해 발생하는 손실을 합산한 다음 한꺼번에 이루어지게 되는데, 이 단위를 '배치(Batch)'라고 함\n",
    "- 딥러닝의 학습은 하나의 배치에 대해서 발생한 손실을 최소화시키는 방향으로 가중치를 조정하며 수행됨\n",
    "- 해당 방향으로 이동하는 크기를 결정하는 것이 학습률임\n",
    "- 딥러닝의 학습에 있어 학습의 방향을 다변화할 수 있음\n",
    "- 최적화 도구(Optimizer)는 이를 위해 사용됨\n",
    "- 텐서플로우, 케라스는 딥러닝 네트워크를 손쉽게 구성할 수 있도록 하는 파이썬의 라이브러리임\n",
    "- 각 층의 출력은 활성화 함수를 사용하여 특정 범위로 조정할 수 있으며, 최근 가장 보편적으로 사용되는 활성화 함수는 ReLU 임"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

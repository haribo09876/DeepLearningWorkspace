{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 순환 신경망과 파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM은 시계열 데이터를 효과적으로 학습하기 위해 개발된 순환 네트워크의 한 종류\n",
    "- 순환 신경망은 완전 연결 신경망에 비해 적은 수의 가중치로 신호의 변화를 효과적으로 학습할수 있으며, 이에 따라 가속도센서, 자이로센서와 같은 각종 디지털 센서로부터 측정되는 데이터, 자연어 처리 등에 널리 사용되고 있음\n",
    "- 단순 순환 신경망(RNN, Simple Recurrent Neural Network)은 순환 네트워크의 한 종류로 LSTM에 비해 구조가 단순\n",
    "- (LSTM의 특징)\n",
    "- 데이터 흐름이 이원화(tanh를 거치지 않고 변화하는 셀 상태, tanh를 통해-1 ~ 1의 범위로 정규화된 출력)되어 있음\n",
    "- 게이트(Forget Gate, Input Gate, Output Gate)를 통해 흐름을 막거나 열 수 있음\n",
    "- 출력 노드 1개에 대해 4개의 가중치가 구성\n",
    "- 데이터 시퀀스의 각 입력에 대해 가중치를 공유하여 각 입력을 포괄적으로 나타낼 수 있는 모델을 생성\n",
    "- 입력에 따라 게이트의 열린 정도를 다르게 설정할 수 있으므로, 게이트 가중치가 동일하더라도 다양항 패턴의 학습이 가능\n",
    "- 단순 RNN에 비해 긴 패턴의 학습이 가능\n",
    "- 합성곱층에서 조정 가능한 주요 파라미터는 필터 수, 커널 크기, 활성화 함수, 풀링층의 풀/스트라이드 크기, 풀링층의 종류, 활성화 함수의 종류가 있음\n",
    "- LSTM층에서 조정 가능한 주요 파라미터는 노드 수, 출력 형태, 양방향 여부 등이 있음\n",
    "- 완전 연결층에서 조정 가능한 주요 파라미터는 유닛 수, 활성화 함수의 종류 등\n",
    "- 모델 생성 시의 파라미터는 학습률, 최적화 도구의 종류, 손실함수 등임\n",
    "- 학습 시에 조정해야 하는 기본적인 파라미터는 '에포크 수(epoches)', '배치 크기(batch_size)', '검증 데이터 비율(validation_split)' 등\n",
    "- Confusion Matrix는 여러 데이터 중 어떤 패턴이 문제를 많이 발생시켰는지를 확인하는 데 사용되는 도구\n",
    "- 파라미터의 최적화에 들어가기에 앞서, 달성하고자 하는 목표 정확도를 정하는 것이 좋음\n",
    "- 파라미터의 최적화 초기에는 오버피팅을 감수하며 학습 정확도를 높이는 데에 치중하는 것이 좋다고 알려져 있음\n",
    "- 이후 네트워크의 크기를 줄이고 드롭아웃 등을 추가하면서 오버피팅의 크기를 감소시켜 가며 최적화를 수행"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
